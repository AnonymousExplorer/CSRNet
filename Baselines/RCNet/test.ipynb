{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import datasets\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "test_dataset = datasets.helen_data.Helen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DataLoader(test_dataset,batch_size=2,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = models.RCNet.RCNet().cuda()\n",
    "net.load_state_dict(torch.load('/home/zelin/csrnet/Baseline/RCNet/checkpoints/rcnet_050000.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "net.eval()\n",
    "for path in glob('/home/zelin/csrnet/Dataset/CelebA/*'):\n",
    "    hr = Image.open(path)\n",
    "    lr = hr.resize((24,24),Image.BILINEAR).resize((192,192),Image.BILINEAR)\n",
    "    lr = torchvision.transforms.ToTensor()(lr).float().cuda()\n",
    "    with torch.no_grad():\n",
    "        coarse_sr,refine_sr,lds = net(lr.unsqueeze(0))\n",
    "        torchvision.utils.save_image(refine_sr[-1],'results/celeba_/%s'%path.split('/')[-1].replace('jpg','png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "net.eval()\n",
    "for path in glob('/home/zelin/csrnet/Dataset/helen/*'):\n",
    "    hr = Image.open(path)\n",
    "    lr = hr.resize((24,24),Image.BILINEAR).resize((192,192),Image.BILINEAR)\n",
    "    lr = torchvision.transforms.ToTensor()(lr).float().cuda()\n",
    "    with torch.no_grad():\n",
    "        coarse_sr,refine_sr,lds = net(lr.unsqueeze(0))\n",
    "        torchvision.utils.save_image(coarse_sr[-1],'results/helen_/%s'%path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr = 0\n",
    "for j,test_ in enumerate(test_data):\n",
    "    net.eval()\n",
    "    lr,hr = test_\n",
    "    lr = lr.float().cuda()\n",
    "    hr = hr.float().cuda()\n",
    "    with torch.no_grad():\n",
    "        coarse_sr,refine_sr,lds = net(lr)\n",
    "        mse = ((refine_sr[-1]-hr)**2).mean(dim=[1,2,3])\n",
    "        psnr += (10*torch.log10(1/mse)).mean()\n",
    "    torchvision.utils.save_image(refine_sr[-1],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "def calculate_psnr(img1, img2):\n",
    "    # img1 and img2 have range [0, 255]\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    mse = np.mean((img1 - img2)**2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * math.log10(255.0 / math.sqrt(mse))\n",
    "\n",
    "def ssim(img1, img2):\n",
    "    C1 = (0.01 * 255)**2\n",
    "    C2 = (0.03 * 255)**2\n",
    "\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
    "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "    mu1_sq = mu1**2\n",
    "    mu2_sq = mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
    "                                                            (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    '''calculate SSIM\n",
    "    the same outputs as MATLAB's\n",
    "    img1, img2: [0, 255]\n",
    "    '''\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "    if img1.ndim == 2:\n",
    "        return ssim(img1, img2)\n",
    "    elif img1.ndim == 3:\n",
    "        if img1.shape[2] == 3:\n",
    "            ssims = []\n",
    "            for i in range(img1.shape[2]):\n",
    "                ssims.append(ssim(img1[..., i], img2[..., i]))\n",
    "            return np.array(ssims).mean()\n",
    "        elif img1.shape[2] == 1:\n",
    "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
    "    else:\n",
    "        raise ValueError('Wrong input image dimensions.')\n",
    "\n",
    "def bgr2ycbcr(img, only_y=True):\n",
    "    '''same as matlab rgb2ycbcr\n",
    "    only_y: only return Y channel\n",
    "    Input:\n",
    "        uint8, [0, 255]\n",
    "        float, [0, 1]\n",
    "    '''\n",
    "    in_img_type = img.dtype\n",
    "    img.astype(np.float32)\n",
    "    if in_img_type != np.uint8:\n",
    "        img *= 255.\n",
    "    # convert\n",
    "    if only_y:\n",
    "        rlt = np.dot(img, [24.966, 128.553, 65.481]) / 255.0 + 16.0\n",
    "    else:\n",
    "        rlt = np.matmul(img, [[24.966, 112.0, -18.214], [128.553, -74.203, -93.786],\n",
    "                              [65.481, -37.797, 112.0]]) / 255.0 + [16, 128, 128]\n",
    "    if in_img_type == np.uint8:\n",
    "        rlt = rlt.round()\n",
    "    else:\n",
    "        rlt /= 255.\n",
    "    return rlt.astype(in_img_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26.057283305605388, 0.7424278535132259)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "psnr_,ssim_,count = 0, 0, 0\n",
    "for path in glob('/home/zelin/csrnet/Dataset/helen/*'):\n",
    "    hr = np.array(Image.open(path))\n",
    "    sr = np.array(Image.open(path.replace('Dataset/helen/','Baseline/RCNet/results/helen_/')))\n",
    "    hr = bgr2ycbcr(hr)\n",
    "    sr = bgr2ycbcr(sr)\n",
    "    ssim_ += calculate_ssim(hr,sr)\n",
    "    psnr_ += calculate_psnr(hr,sr)\n",
    "    count += 1\n",
    "\n",
    "psnr_/count,ssim_/count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.176137249489248, 0.7077050334405388)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "psnr_,ssim_,count = 0, 0, 0\n",
    "for path in glob('/home/zelin/csrnet/Dataset/CelebA/*'):\n",
    "    hr = np.array(Image.open(path))\n",
    "    sr = np.array(Image.open(path.replace('Dataset/CelebA/','Baseline/RCNet/results/celeba/').replace('jpg','png')))\n",
    "    hr = bgr2ycbcr(hr)\n",
    "    sr = bgr2ycbcr(sr)\n",
    "    ssim_ += calculate_ssim(hr,sr)\n",
    "    psnr_ += calculate_psnr(hr,sr)\n",
    "    count += 1\n",
    "\n",
    "psnr_/count,ssim_/count\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GFPGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ae5fbbaf211f8a9f91e526e056ad9c71f45571819b0a98419fe9c24eb5cd63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
